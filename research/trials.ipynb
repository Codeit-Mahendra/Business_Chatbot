{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b843c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e072f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from PDF files\n",
    "def load_pdf_files(data):\n",
    "    loader = DirectoryLoader(\n",
    "        data,\n",
    "        glob=\"*.pdf\",\n",
    "        loader_cls=PyPDFLoader\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "002dda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_documents = load_pdf_files(\"E:/7. ML practise Daily/7. GEN AI/11. Chatbot_Github_end to end/Business_Chatbot/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72756806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents extracted: 176\n"
     ]
    }
   ],
   "source": [
    "length = len(extracted_documents)\n",
    "print(f\"Total number of documents extracted: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94348b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extracted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d88df17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 14.0 (Windows)', 'creationdate': '2020-08-03T12:26:17+01:00', 'moddate': '2020-08-03T12:26:41+01:00', 'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Data.pdf', 'total_pages': 40, 'page': 0, 'page_label': '1'}, page_content='Three Short\\nNovels\\nEdited by\\nAngela Esterhammer\\nThe Edinburgh Edition of  the Works of\\nJohn Galt\\nThe three novels collected in this volume  \\nreveal the diversity of  Galt’s creative abilities. \\nGlenfell (1820) is his first publication in the style \\nof  Scottish fiction for which he would become \\nbest known; Andrew of  Padua, the Improvisatore \\n(1820) is a unique synthesis of  his experiences \\nwith theatre, educational writing, and travel; \\nThe Omen (1825) is a haunting gothic tale. With \\ntheir easily readable scope and their vivid \\nthemes, each of  the stories has a distinct charm. \\nThey cast light on significant phases of  Galt’s \\ncareer as a writer and show his versatility in \\nexperimenting with themes, genres, and styles.\\nThis volume reproduces Galt’s original editions, \\nmaking these virtually unknown works available \\nto modern readers while setting them into \\nthe context in which they were first published \\nand read. Full annotations explain Galt’s \\ndiverse geographical, historical, literary , and \\nphilosophical contexts and allusions.  \\nA comprehensive introduction reveals the \\nnovels’ contemporary reception and their \\nsignificance within Galt’s life and career.\\nAngela Esterhammer, FRSC, is Professor of  \\nEnglish and Principal of  Victoria College in the \\nUniversity of  Toronto.\\nCover design: Stuart Dalziel\\nBack cover image: Sketch of  John Galt by Daniel Maclise, \\nFraser’s Magazine, December 1830. Courtesy of  University of  \\nToronto Libraries and Victoria University Library (Toronto).\\nEdinburgh Edition of  the Works of  John Galt\\nThree Short Novels\\nEdited by\\nAngela Esterhammer\\nThe Edinburgh Edition of  the Works of\\nJohn Galt\\nGeneral Editor: Angela Esterhammer\\nJohn Galt (1779–1839) was among the most \\npopular and prolific Scottish writers of  the \\nnineteenth century . He wrote in a panoply of  \\nforms and genres about a great variety of  topics \\nand settings, drawing on his experiences of  \\nliving, working, and travelling in Scotland and \\nEngland, in Europe and the Mediterranean, \\nand in North America. While he is best known \\nfor his humorous tales and serious sagas about \\nScottish life, his fiction spans many other genres \\nincluding historical novels, gothic tales, political \\nsatire, travel narratives, and short stories.\\nThe Edinburgh Edition of  the Works of  John Galt is \\nthe first-ever scholarly edition of  Galt’s fiction; \\nit presents a wide range of  Galt’s works, some \\nof  which have never been reprinted. The \\nseries contains authoritative texts together with \\nmaterials that add to an appreciation of  Galt’s \\nhistorical context, his cultural heritage, and his \\noverall importance within literary history .\\nEdinburgh Edition of  the Works of\\nGlenfell\\nAndrew of  Padua, the Improvisatore\\nThe Omen\\n2412 eup Esterhammer_JKT.indd   1 26/02/2020   22:18'),\n",
       " Document(metadata={'producer': 'Adobe PDF Library 15.0', 'creator': 'Adobe InDesign 14.0 (Windows)', 'creationdate': '2020-08-03T12:26:17+01:00', 'moddate': '2020-08-03T12:26:41+01:00', 'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Data.pdf', 'total_pages': 40, 'page': 1, 'page_label': '2'}, page_content='Three Short Novels\\nGlenfell\\nAndrew of Padua, the Improvisatore\\nThe Omen\\nThe Edinburgh Edition of the Works of John Galt\\nGeneral Editor: Angela Esterhammer')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_documents[0:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c833246",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document\n",
    "\n",
    "def filter_to_minimal_docs(docs: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Given a list of Document objects, return a new list of Document objects\n",
    "    containing only 'source' in metadata and the original page_content.\n",
    "    \"\"\"\n",
    "    minimal_docs: List[Document] = []\n",
    "    for doc in docs:\n",
    "        # Get source from original metadata (returns None if not found)\n",
    "        src = doc.metadata.get(\"source\")\n",
    "        \n",
    "        # Create new Document with only page_content and source metadata\n",
    "        minimal_docs.append(\n",
    "            Document(\n",
    "                page_content=doc.page_content,  # Keep original content\n",
    "                metadata={\"source\": src}        # Keep only source in metadata\n",
    "            )\n",
    "        )\n",
    "    return minimal_docs\n",
    "\n",
    "# This function filters documents to minimal metadata - keeps only source and content\n",
    "# Useful for reducing document size and removing unnecessary metadata before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c11c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal_documents = filter_to_minimal_docs(extracted_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18d4d667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Data.pdf'}, page_content='Three Short\\nNovels\\nEdited by\\nAngela Esterhammer\\nThe Edinburgh Edition of  the Works of\\nJohn Galt\\nThe three novels collected in this volume  \\nreveal the diversity of  Galt’s creative abilities. \\nGlenfell (1820) is his first publication in the style \\nof  Scottish fiction for which he would become \\nbest known; Andrew of  Padua, the Improvisatore \\n(1820) is a unique synthesis of  his experiences \\nwith theatre, educational writing, and travel; \\nThe Omen (1825) is a haunting gothic tale. With \\ntheir easily readable scope and their vivid \\nthemes, each of  the stories has a distinct charm. \\nThey cast light on significant phases of  Galt’s \\ncareer as a writer and show his versatility in \\nexperimenting with themes, genres, and styles.\\nThis volume reproduces Galt’s original editions, \\nmaking these virtually unknown works available \\nto modern readers while setting them into \\nthe context in which they were first published \\nand read. Full annotations explain Galt’s \\ndiverse geographical, historical, literary , and \\nphilosophical contexts and allusions.  \\nA comprehensive introduction reveals the \\nnovels’ contemporary reception and their \\nsignificance within Galt’s life and career.\\nAngela Esterhammer, FRSC, is Professor of  \\nEnglish and Principal of  Victoria College in the \\nUniversity of  Toronto.\\nCover design: Stuart Dalziel\\nBack cover image: Sketch of  John Galt by Daniel Maclise, \\nFraser’s Magazine, December 1830. Courtesy of  University of  \\nToronto Libraries and Victoria University Library (Toronto).\\nEdinburgh Edition of  the Works of  John Galt\\nThree Short Novels\\nEdited by\\nAngela Esterhammer\\nThe Edinburgh Edition of  the Works of\\nJohn Galt\\nGeneral Editor: Angela Esterhammer\\nJohn Galt (1779–1839) was among the most \\npopular and prolific Scottish writers of  the \\nnineteenth century . He wrote in a panoply of  \\nforms and genres about a great variety of  topics \\nand settings, drawing on his experiences of  \\nliving, working, and travelling in Scotland and \\nEngland, in Europe and the Mediterranean, \\nand in North America. While he is best known \\nfor his humorous tales and serious sagas about \\nScottish life, his fiction spans many other genres \\nincluding historical novels, gothic tales, political \\nsatire, travel narratives, and short stories.\\nThe Edinburgh Edition of  the Works of  John Galt is \\nthe first-ever scholarly edition of  Galt’s fiction; \\nit presents a wide range of  Galt’s works, some \\nof  which have never been reprinted. The \\nseries contains authoritative texts together with \\nmaterials that add to an appreciation of  Galt’s \\nhistorical context, his cultural heritage, and his \\noverall importance within literary history .\\nEdinburgh Edition of  the Works of\\nGlenfell\\nAndrew of  Padua, the Improvisatore\\nThe Omen\\n2412 eup Esterhammer_JKT.indd   1 26/02/2020   22:18'),\n",
       " Document(metadata={'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Data.pdf'}, page_content='Three Short Novels\\nGlenfell\\nAndrew of Padua, the Improvisatore\\nThe Omen\\nThe Edinburgh Edition of the Works of John Galt\\nGeneral Editor: Angela Esterhammer')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimal_documents[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bd468ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_splitter(minimal_documents: List[Document]) -> List[Document]:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    texts_chunk = text_splitter.split_documents(minimal_documents)\n",
    "    return texts_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40522097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of text chunks: 623\n"
     ]
    }
   ],
   "source": [
    "texts_chunk = text_splitter(minimal_documents)\n",
    "print(f\"Total number of text chunks: {len(texts_chunk)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a6469d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_embeddings():\n",
    "    \"\"\"\n",
    "    Download and return the HuggingFace embeddings model.\n",
    "    \"\"\"\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "    embeddings = HuggingFaceEmbeddings(\n",
    "        model_name=model_name\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "embedding = download_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c7cf9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = embedding.embed_query(\"Hello world\")\n",
    "# vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d66c34a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4afbb5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "# load_dotenv()\n",
    "\n",
    "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "# # OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "# OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"phi3:mini\")  # fallback if not set\n",
    "\n",
    "# # os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "984d4cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Get environment variables\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "HUGGINGFACE_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "OLLAMA_MODEL = os.getenv(\"OLLAMA_MODEL\", \"phi3:mini\")\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = HUGGINGFACE_API_TOKEN\n",
    "\n",
    "# Now you can use Hugging Face Inference API\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "def get_llm_response(prompt):\n",
    "    client = InferenceClient(token=HUGGINGFACE_API_TOKEN)\n",
    "    response = client.text_generation(\n",
    "        prompt,\n",
    "        model=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "        max_new_tokens=500,\n",
    "        temperature=0.8\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5d9fd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone \n",
    "pinecone_api_key = PINECONE_API_KEY\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1a06bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.pinecone.Pinecone at 0x1715710af20>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "312aaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec \n",
    "\n",
    "index_name = \"business-chatbot\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name = index_name,\n",
    "        dimension=384,  # Dimension of the embeddings\n",
    "        metric= \"cosine\",  # Cosine similarity\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "\n",
    "\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cb650b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=texts_chunk,\n",
    "    embedding=embedding,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "977f95d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load Existing index \n",
    "\n",
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# # Embed each chunk and upsert the embeddings into your Pinecone index.\n",
    "# docsearch = PineconeVectorStore.from_existing_index(\n",
    "#     index_name=index_name,\n",
    "#     embedding=embedding\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a194f8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ba297ede-43fd-4d25-bb7f-e7656283cabf']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dswith = Document(\n",
    "    page_content=\"Mahendra is so awesome person.\",\n",
    "    metadata={\"source\": \"Blog\"}\n",
    ")\n",
    "\n",
    "docsearch.add_documents(documents=[dswith])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d7c1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fa1d13a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='d18194e0-09eb-481e-a439-fe880780b355', metadata={'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 226\\nAcne\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 26'),\n",
       " Document(id='078a3376-dd34-421f-b283-594a72fad395', metadata={'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Medical_book.pdf'}, page_content='GALE ENCYCLOPEDIA OF MEDICINE 2 25\\nAcne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceous\\nglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)\\nGEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(id='58e419ac-25c2-49a5-a5f5-eadb469cf2bf', metadata={'source': 'E:\\\\7. ML practise Daily\\\\7. GEN AI\\\\11. Chatbot_Github_end to end\\\\Business_Chatbot\\\\data\\\\Medical_book.pdf'}, page_content='Acidosis see Respiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when the\\npores of the skin become clogged with oil, dead skin\\ncells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is\\nthe most common skin disease. It affects nearly 17 million\\npeople in the United States. While acne can arise at any')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Acne?\")\n",
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f70a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "\n",
    "chatModel = Ollama(model=OLLAMA_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a1f3ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bbc08349",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"You are an General story assistant for question-answering tasks. You understand the context very well and Guide us for answers very precisly \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use two sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "351cd89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(chatModel, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b597fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sudha Murty is an Indian educator, social worker, and prolific writer born in Shiggaon, Karnataka, in 1950. She received the Padma Shri Award for Literature and has authored numerous books that have been translated into various Indian languages.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Who is sudha murthy ?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be674b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The children went with their grandmother, Ajja.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Who did the children go with to the paddy fields ?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca1ab9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the city where most things come from supermarkets, witnessing how food is grown and produced through farming was a novel experience for them. The sight of clean seeds being prepared or separating straw from paddy showed them behind-the-scenes work that isn't apparent in everyday urban life.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"Why were the children surprised by the farming activities they saw?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b639e649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ajji's story suggests that a person can overcome poverty through intelligence and being helpful to others. The woman in her tale demonstrates this by using clever methods, such as selling tree fruit directly from trees rather than relying on intermediaries like wholesalers or supermarkets.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What does Ajji’s story suggest about the role of intelligence and resourcefulness in overcoming poverty??\"})\n",
    "print(response[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
